# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pymatgen import Composition
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from matminer.featurizers.conversions import StrToComposition
from matminer.featurizers.composition import ElementProperty

# Step 1: Load the dataset
# For this example, we'll use a pre-downloaded dataset from the Materials Project
# You can replace this with data fetched using the Materials Project API
data = pd.read_csv("https://raw.githubusercontent.com/materialsvirtuallab/matminer/master/matminer/datasets/materials_project_bandgap.csv")

# Display the first few rows of the dataset
print(data.head())

# Step 2: Data Preprocessing
# Convert composition strings to pymatgen Composition objects
data = StrToComposition().featurize_dataframe(data, "formula")

# Step 3: Feature Engineering
# Use ElementProperty to generate composition-based features
ep_featurizer = ElementProperty.from_preset("magpie")
data = ep_featurizer.featurize_dataframe(data, col_id="composition")

# Drop rows with missing values
data = data.dropna()

# Step 4: Define Features and Target
# Features: All elemental property features
# Target: Bandgap energy (band_gap)
X = data.drop(columns=["formula", "composition", "band_gap"])
y = data["band_gap"]

# Step 5: Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 6: Train a Machine Learning Model
# Use Random Forest Regressor
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Step 7: Evaluate the Model
# Predict on the test set
y_pred = model.predict(X_test)

# Calculate evaluation metrics
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error: {mae:.4f}")
print(f"RÂ² Score: {r2:.4f}")

# Step 8: Visualize Results
# Plot actual vs predicted bandgap values
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color="red", linestyle="--")
plt.xlabel("Actual Bandgap (eV)")
plt.ylabel("Predicted Bandgap (eV)")
plt.title("Actual vs Predicted Bandgap")
plt.show()

# Plot feature importance
feature_importance = pd.Series(model.feature_importances_, index=X.columns)
feature_importance.sort_values(ascending=False).head(20).plot(kind="bar", figsize=(10, 6))
plt.title("Top 20 Feature Importances")
plt.xlabel("Features")
plt.ylabel("Importance")
plt.show()
